# ğŸ“š TRABAJO PRÃCTICO: DECISION TRANSFORMER PARA RECOMENDACIONES

---

## ğŸ¬ğŸ“š ELECCIÃ“N DE DATASET

Este trabajo prÃ¡ctico permite a cada grupo elegir entre **dos dominios diferentes**:

| Dataset | Items | Dominio | CaracterÃ­sticas |
|---------|-------|---------|-----------------|
| **ğŸ¬ Netflix** | 752 pelÃ­culas | PelÃ­culas/series | Recomendado, dominio familiar |
| **ğŸ“š Goodreads** | 472 libros | Libros | Alternativa, menos items (training mÃ¡s rÃ¡pido) |

âœ… **Ambos tienen la misma estructura** - El cÃ³digo es idÃ©ntico  
âœ… **Solo cambian:** Paths de archivos y nÃºmero de items  
âœ… **Cada grupo elige segÃºn su interÃ©s** - No hay diferencia en dificultad

---

## ğŸ—‚ï¸ Estructura de Documentos

Este trabajo prÃ¡ctico cuenta con **2 documentos principales**:

---

### 1ï¸âƒ£ **03_REFERENCIA_COMPLETA.md** (Documento Principal)
ğŸ“„ **[Leer aquÃ­](./03_REFERENCIA_COMPLETA.md)**

**Contenido:**
- âœ… DescripciÃ³n completa del problema
- âœ… ExplicaciÃ³n detallada de los datasets disponibles (Netflix o Goodreads)
- âœ… CÃ³digo de REFERENCIA completo (Decision Transformer, training, evaluation)
- âœ… Especificaciones tÃ©cnicas de cada parte
- âœ… Criterios de evaluaciÃ³n

**CuÃ¡ndo usarlo:**
- Para entender el problema a fondo
- Para ver ejemplos de cÃ³digo funcionando
- Para consultar detalles tÃ©cnicos

---

### 2ï¸âƒ£ **02_GUIA_IMPLEMENTACION_GRUPOS.md** (GuÃ­a PrÃ¡ctica) â­
ğŸ“„ **[Leer aquÃ­](./02_GUIA_IMPLEMENTACION_GRUPOS.md)**

**Contenido:**
- âœ… QUÃ‰ implementar vs QUÃ‰ es cÃ³digo de referencia
- âœ… Checklist paso a paso de tareas
- âœ… Esqueletos de cÃ³digo con TODOs
- âœ… Criterios de Ã©xito para cada parte
- âœ… Consejos y troubleshooting

**CuÃ¡ndo usarlo:**
- **Â¡EMPEZAR POR AQUÃ!** ğŸ‘ˆ
- Cuando el grupo no sepa por dÃ³nde empezar
- Para verificar que no falta nada
- Durante la implementaciÃ³n (checklist)

---

## ğŸ”§ PASO 0: CONFIGURACIÃ“N INICIAL

Antes de empezar, el grupo debe elegir el dataset:

1. **Abre** `config_dataset.py`
2. **Modifica** la lÃ­nea:
   ```python
   DATASET = 'netflix'    # Cambiar a 'goodreads' si prefieren libros
   ```
3. **Verifica** ejecutando: `python config_dataset.py`

âœ… Todo el cÃ³digo del grupo usarÃ¡ este dataset automÃ¡ticamente

---

## ğŸ“¦ Estructura de Entrega Esperada

```
apellido_nombre_tp_dt/
â”‚
â”œâ”€â”€ data/                          # (proporcionado - no entregar)
â”‚   â”œâ”€â”€ train/netflix8_train.df
â”‚   â””â”€â”€ test_users/netflix8_test.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion_dataset.ipynb       âœ… Parte 1
â”‚   â”œâ”€â”€ 02_training.ipynb                  âœ… Parte 2
â”‚   â”œâ”€â”€ 03_evaluation.ipynb                âœ… Parte 3
â”‚   â””â”€â”€ 04_return_conditioning.ipynb       âœ… Parte 4
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ load_data.py                   âœ… Implementar
â”‚   â”‚   â”œâ”€â”€ preprocessing.py               âœ… Implementar
â”‚   â”‚   â””â”€â”€ dataset.py                     âœ… Implementar
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ decision_transformer.py        âœ… Copiar/adaptar
â”‚   â”‚   â””â”€â”€ baselines.py                   âœ… Implementar
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py                     âœ… Implementar
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py                     âœ… Implementar
â”‚       â””â”€â”€ evaluate.py                    âœ… Implementar
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                           âœ… GrÃ¡ficos generados
â”‚   â”œâ”€â”€ logs/                              âœ… Logs de training
â”‚   â””â”€â”€ checkpoints/                       âœ… Modelo entrenado
â”‚
â”œâ”€â”€ REPORTE.pdf                            âœ… Parte 5 (3-5 pÃ¡ginas)
â”œâ”€â”€ README.md                              âœ… Instrucciones de uso
â””â”€â”€ requirements.txt                       âœ… Dependencias
```

---

## ğŸ“Š Criterios de EvaluaciÃ³n

La evaluaciÃ³n del trabajo prÃ¡ctico se basa en los siguientes componentes:

### **Parte 1: ExploraciÃ³n y PreparaciÃ³n del Dataset**

**Se evalÃºa:**
- AnÃ¡lisis exploratorio completo (distribuciones, estadÃ­sticas clave)
- Visualizaciones claras e informativas (mÃ­nimo 3 grÃ¡ficos relevantes)
- Correcta implementaciÃ³n del preprocesamiento (returns-to-go, formato DT)
- ValidaciÃ³n de que los datos procesados son correctos

**Entregables:**
- Notebook `01_exploracion_dataset.ipynb` ejecutado
- Script `data_preprocessing.py` funcional
- Dataset procesado guardado

---

### **Parte 2: ImplementaciÃ³n del Modelo**

**Se evalÃºa:**
- Arquitectura del Decision Transformer funcional
- Training loop implementado correctamente
- Dataset y DataLoader de PyTorch funcionando
- El loss disminuye durante el entrenamiento
- Modelo entrenado guardado (checkpoint)

**Entregables:**
- `src/models/decision_transformer.py`
- `src/data/dataset.py`
- `src/training/trainer.py`
- Notebook `02_training.ipynb` con logs y grÃ¡ficos de loss
- Modelo entrenado (`.pth` o `.pt`)

---

### **Parte 3: Baselines y EvaluaciÃ³n**

**Se evalÃºa:**
- ImplementaciÃ³n de al menos 1 baseline (ej: Popularity, Behavior Cloning)
- MÃ©tricas correctamente implementadas (Hit Rate@K, NDCG@K, MRR)
- EvaluaciÃ³n completa en test set (cold-start users)
- Tabla comparativa de resultados (DT vs Baselines)

**Entregables:**
- `src/models/baselines.py`
- `src/evaluation/metrics.py`
- `src/evaluation/evaluate.py`
- Notebook `03_evaluation.ipynb` con resultados

---

### **Parte 4: Experimentos con Return Conditioning**

**Se evalÃºa:**
- AnÃ¡lisis del efecto de diferentes valores de RÌ‚ objetivo
- GrÃ¡ficos mostrando Return vs Performance
- AnÃ¡lisis de performance por grupo de usuarios
- InterpretaciÃ³n de resultados (Â¿el conditioning funciona?)

**Entregables:**
- Notebook `04_return_conditioning.ipynb` ejecutado
- GrÃ¡ficos claros del efecto del conditioning
- AnÃ¡lisis cold-start por grupo

---

### **Parte 5: Reporte Final**

**Se evalÃºa:**
- Claridad en la presentaciÃ³n del problema y soluciÃ³n
- Correcta explicaciÃ³n de la metodologÃ­a
- AnÃ¡lisis crÃ­tico de resultados
- Conclusiones bien fundamentadas
- Calidad de visualizaciones y presentaciÃ³n

**Entregables:**
- `REPORTE.pdf` (3-5 pÃ¡ginas)
- Incluye: IntroducciÃ³n, MetodologÃ­a, Resultados, Conclusiones

---

### **Trabajo Adicional (Opcional)**

**Puede incluir:**
- ImplementaciÃ³n propia del transformer (en vez de copiar cÃ³digo de referencia)
- ComparaciÃ³n con baselines adicionales (ej: Matrix Factorization, LSTM)
- AnÃ¡lisis de attention weights y embeddings (t-SNE)
- Experimentos creativos (ej: multi-objective conditioning)
- CÃ³digo particularmente bien documentado y organizado

---

### **Aspectos Generales Evaluados en Todo el TP:**

âœ… **CÃ³digo:** Funcional, legible, bien organizado  
âœ… **Reproducibilidad:** Instrucciones claras, semilla fijada, requirements.txt  
âœ… **DocumentaciÃ³n:** Comentarios Ãºtiles, README con instrucciones de uso  
âœ… **PresentaciÃ³n:** Notebooks ejecutables, grÃ¡ficos profesionales

---

## ğŸ’¡ Recursos Adicionales

### **Papers:**
- Decision Transformer: [https://arxiv.org/abs/2106.01345](https://arxiv.org/abs/2106.01345)
- RLT4Rec: [https://arxiv.org/abs/2412.07403](https://arxiv.org/abs/2412.07403)
- Offline RL Tutorial: [https://arxiv.org/abs/2005.01643](https://arxiv.org/abs/2005.01643)

### **CÃ³digo de Referencia:**
- Decision Transformer oficial: [https://github.com/kzl/decision-transformer](https://github.com/kzl/decision-transformer)
- RLT4Rec repo: [https://github.com/dilina-r/RLT4Rec](https://github.com/dilina-r/RLT4Rec)
- MinGPT (transformers simples): [https://github.com/karpathy/minGPT](https://github.com/karpathy/minGPT)

### **Tutoriales PyTorch:**
- Transformers: [https://pytorch.org/tutorials/beginner/transformer_tutorial.html](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)
- Custom Datasets: [https://pytorch.org/tutorials/beginner/data_loading_tutorial.html](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)

---

## â“ FAQ

**Q: Â¿CÃ³mo se conforma un grupo?**
A: MÃ¡ximo 3 personas.

**Q: Â¿DÃ³nde conseguimos el dataset?**
A: EstÃ¡ en la carpeta `data/` del repositorio. Pueden elegir entre Netflix (pelÃ­culas) o Goodreads (libros).

**Q: Â¿Necesitamos GPU?**
A: Recomendado pero no obligatorio. Google Colab gratuito tiene GPU suficiente.

**Q: Â¿CuÃ¡nto tarda el training?**
A: En GPU: 1-2 horas. En CPU: 4-8 horas.

**Q: Nuestro modelo no mejora, Â¿quÃ© hacemos?**
A: 
1. Verificar preprocesamiento (returns-to-go correctos?)
2. Verificar shapes de tensores
3. Probar learning rate mÃ¡s bajo (1e-5)
4. Verificar causal mask del transformer

**Q: Â¿QuÃ© specs de hardware mÃ­nimas?**
A: 8GB RAM, 10GB espacio disco. GPU opcional.

