# üéØ GU√çA DE IMPLEMENTACI√ìN PARA GRUPOS
## Decision Transformer para Recomendaciones

Esta gu√≠a clarifica **QU√â DEBE IMPLEMENTAR CADA GRUPO** vs **QU√â ES C√ìDIGO DE REFERENCIA**

---

## üé¨üìö IMPORTANTE: ELEGIR DATASET

Antes de empezar, elige uno de estos dos datasets:

| Dataset | Items | Dominio | Dificultad |
|---------|-------|---------|------------|
| **Netflix** üé¨ | 752 pel√≠culas | Pel√≠culas/series | Media |
| **Goodreads** üìö | 472 libros | Libros | Ligeramente menor |

**Ambos tienen la misma estructura.** Solo cambian:
- N√∫mero de items (`num_items` en el modelo)
- Paths de archivos

**üí° Sugerencia:** Usa Netflix si no tienes preferencia. Usa Goodreads si prefieres dominio de libros o training m√°s r√°pido (menos items).

### **üîß Archivo de Configuraci√≥n Proporcionado**

Para facilitar el cambio entre datasets, se incluye `config_dataset.py`:

```python
# En config_dataset.py, solo modifica esta l√≠nea:
DATASET = 'netflix'    # o 'goodreads'

# Luego, en tu c√≥digo:
from config_dataset import DATASET, NUM_ITEMS, get_paths

paths = get_paths()
df_train = pd.read_pickle(paths['train'])

model = DecisionTransformer(
    num_items=NUM_ITEMS,  # Se ajusta autom√°ticamente
    ...
)
```

**‚úÖ Ventajas:**
- Un solo lugar para cambiar el dataset
- Todos los paths se actualizan autom√°ticamente
- Menos errores de configuraci√≥n

---

## üìã RESUMEN EJECUTIVO

| Componente | ¬øQu√© hacer? | Dificultad | Tiempo est. |
|------------|-------------|------------|-------------|
| **Parte 1: Exploraci√≥n** | Implementar an√°lisis y preprocesamiento | ‚≠ê‚≠ê F√°cil | 4-6 horas |
| **Parte 2: Modelo** | Copiar/adaptar c√≥digo de referencia | ‚≠ê‚≠ê‚≠ê Media | 8-12 horas |
| **Parte 3: Baselines** | Implementar 2-3 m√©todos simples | ‚≠ê‚≠ê F√°cil-Media | 6-8 horas |
| **Parte 4: Experimentos** | Ejecutar y analizar experimentos | ‚≠ê‚≠ê Media | 4-6 horas |
| **Parte 5: Reporte** | Escribir documento final | ‚≠ê‚≠ê Media | 4-6 horas |

**Tiempo total estimado:** 26-38 horas (distribuir en 3-4 semanas)

---

## üö¶ PARTE 1: EXPLORACI√ìN Y PREPARACI√ìN

### ‚úÖ QU√â IMPLEMENTAR

#### **1.1. Script de carga de datos:**

**Archivo:** `src/data/load_data.py`

```python
# üéØ IMPLEMENTAR: Funciones b√°sicas de carga
# Usar el c√≥digo de ejemplo del TP como gu√≠a

import pandas as pd
import json

# ============================================
# CONFIGURACI√ìN: Elegir dataset
# ============================================
DATASET = 'netflix'    # O 'goodreads'
NUM_ITEMS = 752 if DATASET == 'netflix' else 472

def load_training_data(dataset='netflix'):
    """
    Carga el dataset de training.
    
    Args:
        dataset: 'netflix' o 'goodreads'
    
    Returns:
        df: pandas DataFrame con columnas [user_id, user_group, items, ratings]
    """
    path = f'data/train/{dataset}8_train.df'
    # TODO: Implementar carga con pandas
    # df = pd.read_pickle(path)
    # return df
    pass

def load_test_data(dataset='netflix'):
    """
    Carga el dataset de test (cold-start users).
    
    Args:
        dataset: 'netflix' o 'goodreads'
    
    Returns:
        test_users: lista de diccionarios con keys [group, items, ratings]
    """
    path = f'data/test_users/{dataset}8_test.json'
    # TODO: Implementar carga con json
    # with open(path, 'r') as f:
    #     return json.load(f)
    pass

def load_group_centroids(dataset='netflix'):
    """
    Carga centroides de grupos (OPCIONAL).
    
    Args:
        dataset: 'netflix' o 'goodreads'
    
    Returns:
        mu: DataFrame de 8xNUM_ITEMS con ratings promedio por grupo
    """
    path = f'data/groups/mu_{dataset}8.csv'
    # TODO (Opcional): Implementar si quieren usar para baselines
    # mu = pd.read_csv(path, header=None)
    # return mu
    pass
```

**‚úì Criterio de √©xito:** Poder cargar y acceder a los datos sin errores.

---

#### **1.2. An√°lisis Exploratorio:**

**Archivo:** `notebooks/01_exploracion_dataset.ipynb`

```python
# üéØ IMPLEMENTAR: An√°lisis completo del dataset

# === Secci√≥n 1: Estad√≠sticas B√°sicas ===
# TODO:
# - Imprimir n√∫mero de usuarios, items, interacciones
# - Calcular longitud promedio/min/max de secuencias
# - Calcular distribuci√≥n de ratings

# === Secci√≥n 2: Visualizaciones ===
# TODO: Crear al menos 3 gr√°ficos:

# 1. Histograma de longitud de secuencias
import matplotlib.pyplot as plt
# plt.hist(...) 

# 2. Distribuci√≥n de ratings (barplot)
# plt.bar(...)

# 3. Top-20 pel√≠culas m√°s populares
# Contar frecuencia de cada item, ordenar, graficar

# BONUS: Distribuci√≥n de ratings por grupo
```

**‚úì Criterio de √©xito:** Notebook ejecutable con an√°lisis y gr√°ficos claros.

---

#### **1.3. Preprocesamiento:**

**Archivo:** `src/data/preprocessing.py`

```python
# üéØ IMPLEMENTAR: Funci√≥n de preprocesamiento
# El c√≥digo de referencia est√° en el TP - pueden copiarlo y adaptarlo

import numpy as np

def create_dt_dataset(df_train):
    """
    Convierte DataFrame raw a formato Decision Transformer.
    
    REFERENCIA: Ver c√≥digo completo en TRABAJO_PRACTICO_DECISION_TRANSFORMER.md
    
    Args:
        df_train: DataFrame con [user_id, user_group, items, ratings]
    
    Returns:
        trajectories: List[Dict] con formato espec√≠fico
    """
    trajectories = []
    
    for idx, row in df_train.iterrows():
        # TODO: Extraer items, ratings, group
        
        # TODO: Calcular returns-to-go (RÃÇ)
        # Hint: Iterar hacia atr√°s desde el final
        # returns[t] = ratings[t] + returns[t+1]
        
        # TODO: Crear diccionario con formato correcto
        trajectory = {
            'items': ...,
            'ratings': ...,
            'returns_to_go': ...,
            'timesteps': ...,
            'user_group': ...
        }
        
        trajectories.append(trajectory)
    
    return trajectories


def validate_preprocessing(trajectories):
    """
    Valida que el preprocesamiento sea correcto.
    """
    # TODO: Verificar que:
    # - Todas las trayectorias tienen las keys correctas
    # - len(items) == len(ratings) == len(returns_to_go)
    # - returns_to_go[0] == sum(ratings)
    # - returns_to_go[-1] == ratings[-1]
    pass
```

**‚úì Criterio de √©xito:** Generar 16,000 trayectorias con formato correcto y validaciones pasando.

---

## üö¶ PARTE 2: IMPLEMENTACI√ìN DEL MODELO

### ‚ö†Ô∏è OPCI√ìN 1: USAR C√ìDIGO DE REFERENCIA (Recomendado)

El TP incluye **c√≥digo completo** del Decision Transformer. Los grupos pueden:

1. **Copiar** el c√≥digo tal cual del documento `TRABAJO_PRACTICO_DECISION_TRANSFORMER.md`
2. **Pegar** en `src/models/decision_transformer.py`
3. **Leer y entender** cada parte (revisar comentarios)
4. **Ejecutar** para verificar que funciona

**Archivos a crear:**
- `src/models/decision_transformer.py` (copiar c√≥digo del TP)
- `src/models/__init__.py` (vac√≠o o con imports)

**‚úì Criterio de √©xito:** El modelo se instancia sin errores:

```python
from src.models.decision_transformer import DecisionTransformer

model = DecisionTransformer(
    num_items=752,
    num_groups=8,
    hidden_dim=128,
    n_layers=3,
    n_heads=4
)

print(f"Par√°metros totales: {sum(p.numel() for p in model.parameters())}")
# Deber√≠a ser ~10-20M par√°metros
```

---

### üåü OPCI√ìN 2: IMPLEMENTAR DESDE CERO (Opcional - Bonus)

Para grupos que quieren m√°s desaf√≠o:

**Tareas:**

1. **Entender la arquitectura** (ver filminas de notas de orador)
2. **Implementar cada componente:**
   - Embeddings (items, rtg, timesteps, groups)
   - Transformer encoder con causal masking
   - Prediction head para items
   - Forward pass completo

**Referencias √∫tiles:**
- Paper original: Decision Transformer (Chen et al., 2021)
- Tutorial PyTorch: https://pytorch.org/tutorials/beginner/transformer_tutorial.html
- C√≥digo minGPT: https://github.com/karpathy/minGPT

**‚úì Criterio de √©xito:** Mismo que Opci√≥n 1 + entendimiento profundo.

---

### ‚úÖ QU√â IMPLEMENTAR SIEMPRE

#### **2.2. Dataset y DataLoader:**

**Archivo:** `src/data/dataset.py`

```python
# üéØ IMPLEMENTAR: PyTorch Dataset customizado
# C√≥digo de referencia en el TP - adaptar

from torch.utils.data import Dataset
import torch
import numpy as np

class RecommendationDataset(Dataset):
    """
    Dataset para entrenar Decision Transformer.
    """
    def __init__(self, trajectories, context_length=20):
        """
        Args:
            trajectories: Lista de dicts con formato de create_dt_dataset()
            context_length: Ventana de contexto (cu√°ntos timesteps usar)
        """
        # TODO: Guardar trajectories y context_length
        pass
    
    def __len__(self):
        # TODO: Retornar n√∫mero de trayectorias
        pass
    
    def __getitem__(self, idx):
        """
        Retorna un sample para training.
        
        Returns:
            Dict con keys:
                - states: (context_length,) LongTensor de item IDs
                - actions: (context_length,) LongTensor de item IDs  
                - rtg: (context_length, 1) FloatTensor de returns-to-go
                - timesteps: (context_length,) LongTensor de posiciones
                - groups: () LongTensor del grupo del usuario
                - targets: (context_length,) LongTensor - next items a predecir
        """
        # TODO: Ver c√≥digo de referencia en el TP
        # Hint: Extraer ventana de la trayectoria
        # Hint: Targets son los items shifted (pr√≥ximo item a predecir)
        pass
```

**‚úì Criterio de √©xito:** Poder crear DataLoader:

```python
dataset = RecommendationDataset(trajectories, context_length=20)
loader = DataLoader(dataset, batch_size=64, shuffle=True)

# Verificar un batch
batch = next(iter(loader))
print(f"Keys: {batch.keys()}")
print(f"States shape: {batch['states'].shape}")  # (64, 20)
```

---

#### **2.3. Training Loop:**

**Archivo:** `src/training/trainer.py`

```python
# üéØ IMPLEMENTAR: Loop de entrenamiento
# C√≥digo de referencia en el TP

import torch
import torch.nn.functional as F

def train_decision_transformer(model, train_loader, val_loader, 
                               optimizer, device, num_epochs=50):
    """
    Entrena el Decision Transformer.
    
    Args:
        model: Instancia de DecisionTransformer
        train_loader: DataLoader de training
        val_loader: DataLoader de validaci√≥n
        optimizer: torch.optim.Optimizer (ej: Adam)
        device: 'cuda' o 'cpu'
        num_epochs: N√∫mero de √©pocas
    
    Returns:
        model: Modelo entrenado
        history: Dict con losses por √©poca
    """
    model.to(device)
    history = {'train_loss': [], 'val_loss': []}
    
    for epoch in range(num_epochs):
        # === TRAINING ===
        model.train()
        total_train_loss = 0
        
        for batch in train_loader:
            # TODO: Mover batch a device
            # states = batch['states'].to(device)
            # actions = ...
            # rtg = ...
            # timesteps = ...
            # groups = ...
            # targets = ...
            
            # TODO: Forward pass
            # logits = model(states, actions, rtg, timesteps, groups)
            
            # TODO: Compute loss (cross-entropy)
            # Hint: Reshape logits y targets para cross_entropy
            # loss = F.cross_entropy(...)
            
            # TODO: Backprop
            # optimizer.zero_grad()
            # loss.backward()
            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            # optimizer.step()
            
            total_train_loss += loss.item()
        
        avg_train_loss = total_train_loss / len(train_loader)
        
        # === VALIDATION ===
        model.eval()
        with torch.no_grad():
            total_val_loss = 0
            for batch in val_loader:
                # TODO: Similar a training pero sin backprop
                pass
            avg_val_loss = total_val_loss / len(val_loader)
        
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        
        print(f'Epoch {epoch+1}/{num_epochs}:')
        print(f'  Train Loss: {avg_train_loss:.4f}')
        print(f'  Val Loss: {avg_val_loss:.4f}')
    
    return model, history
```

**‚úì Criterio de √©xito:** El loss disminuye durante training (no tiene que converger perfectamente).

---

## üö¶ PARTE 3: BASELINES Y EVALUACI√ìN

### ‚úÖ QU√â IMPLEMENTAR

#### **3.1. Baseline: Popularity**

**Archivo:** `src/models/baselines.py`

```python
# üéØ IMPLEMENTAR: Baselines simples (c√≥digo casi completo en el TP)

import numpy as np

class PopularityRecommender:
    """
    Recomienda items m√°s populares (no personalizados).
    """
    def __init__(self):
        self.item_counts = None
        self.popular_items = None
    
    def fit(self, trajectories):
        """
        Args:
            trajectories: Lista de trayectorias (formato DT)
        """
        # TODO: Contar frecuencia de cada item en el dataset
        # Hint: Concatenar todos los 'items' de todas las trayectorias
        # all_items = np.concatenate([traj['items'] for traj in trajectories])
        # self.item_counts = np.bincount(all_items, minlength=752)
        
        # TODO: Ordenar por frecuencia (m√°s popular primero)
        # self.popular_items = np.argsort(self.item_counts)[::-1]
        pass
    
    def recommend(self, user_history, k=10):
        """
        Recomienda top-k items populares no vistos.
        
        Args:
            user_history: lista de item IDs ya vistos
            k: n√∫mero de recomendaciones
        
        Returns:
            recommendations: lista de k item IDs
        """
        # TODO: Filtrar items ya vistos y retornar top-k
        pass
```

**‚úì Criterio de √©xito:** Puede generar recomendaciones (aunque sean malas).

---

#### **3.2. Baseline: Behavior Cloning (Opcional)**

Implementar un transformer SIN conditioning en RÃÇ (solo predice P(a|s)).

**Nota:** Esto es opcional. Si no tienen tiempo, comparen solo contra Popularity.

---

#### **3.3. M√©tricas de Evaluaci√≥n:**

**Archivo:** `src/evaluation/metrics.py`

```python
# üéØ IMPLEMENTAR: Funciones de m√©tricas
# C√≥digo de referencia disponible en el TP

import torch
import numpy as np

def hit_rate_at_k(predictions, targets, k=10):
    """
    Calcula Hit Rate @K.
    
    Args:
        predictions: (batch, num_items) - scores para cada item
        targets: (batch,) - item verdadero
        k: top-K items
    
    Returns:
        hit_rate: float entre 0 y 1
    """
    # TODO: Ver c√≥digo de referencia en el TP
    # Hint: Usar torch.topk para obtener top-k predicciones
    # Hint: Verificar si target est√° en top-k
    pass

def ndcg_at_k(predictions, targets, k=10):
    """
    Normalized Discounted Cumulative Gain @K.
    """
    # TODO: Ver f√≥rmula en el TP
    # NDCG = DCG / IDCG
    pass

def mrr(predictions, targets):
    """
    Mean Reciprocal Rank.
    """
    # TODO: MRR = promedio de 1/rank del item verdadero
    pass
```

**‚úì Criterio de √©xito:** Las m√©tricas dan valores entre 0 y 1 y son consistentes.

---

#### **3.4. Evaluation Loop:**

**Archivo:** `src/evaluation/evaluate.py`

```python
# üéØ IMPLEMENTAR: Evaluaci√≥n del modelo
# C√≥digo muy detallado en el TP - seguir esa gu√≠a

@torch.no_grad()
def evaluate_model(model, test_data, device, target_return=None, k_list=[5, 10, 20]):
    """
    Eval√∫a el modelo en test set (cold-start users).
    
    Ver c√≥digo completo en TRABAJO_PRACTICO_DECISION_TRANSFORMER.md
    """
    model.eval()
    
    # TODO: Seguir l√≥gica del TP:
    # 1. Para cada usuario de test
    # 2. Simular sesi√≥n: empezar con history vac√≠o
    # 3. Ir "recomendando" items y observando ratings
    # 4. Calcular m√©tricas
    
    pass
```

---

## üö¶ PARTE 4: EXPERIMENTOS

### ‚úÖ QU√â IMPLEMENTAR

#### **4.1. Experimento: Effect of Return**

**Archivo:** `notebooks/04_return_conditioning_experiments.ipynb`

```python
# üéØ IMPLEMENTAR: Experimentar con diferentes RÃÇ

# === Calcular percentiles de returns en training ===
# train_returns = [traj['returns_to_go'][0] for traj in trajectories]
# percentiles = {
#     'p25': np.percentile(train_returns, 25),
#     'p50': np.percentile(train_returns, 50),
#     'p75': np.percentile(train_returns, 75),
#     'p90': np.percentile(train_returns, 90),
#     'max': np.max(train_returns)
# }

# === Evaluar modelo con cada return objetivo ===
# results = {}
# for name, rtg_value in percentiles.items():
#     metrics = evaluate_model(model, test_data, device, target_return=rtg_value)
#     results[name] = metrics

# === Graficar Return vs Performance ===
# plt.plot(rtg_values, hr10_values, ...)
```

**‚úì Criterio de √©xito:** Gr√°fico que muestra c√≥mo cambia Hit Rate con diferentes RÃÇ.

---

#### **4.2. An√°lisis por Grupo:**

```python
# üéØ IMPLEMENTAR: Performance por grupo de usuarios

# === Agrupar test users por grupo ===
# for group_id in range(8):
#     users_in_group = [u for u in test_data if u['group'] == group_id]
#     metrics = evaluate_model(model, users_in_group, device)
#     print(f'Group {group_id}: HR@10={metrics["HR@10"]:.4f}')
```

---

## üö¶ PARTE 5: REPORTE

### ‚úÖ QU√â ENTREGAR

**Archivo:** `REPORTE.pdf` (3-5 p√°ginas)

**Estructura:**

1. **Introducci√≥n** (0.5 p√°g)
   - Contexto del problema
   - Objetivos del TP

2. **Dataset y Preprocesamiento** (1 p√°g)
   - Estad√≠sticas clave
   - Gr√°ficos m√°s importantes
   - Explicaci√≥n del preprocesamiento

3. **Implementaci√≥n** (1 p√°g)
   - Arquitectura del modelo (diagrama simple)
   - Hiperpar√°metros usados
   - Detalles de training

4. **Resultados** (1.5 p√°g)
   - Tabla comparativa: DT vs Baselines
   - Gr√°ficos de experiments
   - An√°lisis de cold-start

5. **Conclusiones** (0.5 p√°g)
   - Lecciones aprendidas
   - Ventajas/limitaciones observadas

---

## üìù CHECKLIST FINAL

Antes de entregar, verificar que tienen:

### Parte 1:
- [ ] `src/data/load_data.py` funcional
- [ ] `src/data/preprocessing.py` con `create_dt_dataset()` implementada
- [ ] `notebooks/01_exploracion_dataset.ipynb` ejecutado con gr√°ficos
- [ ] Dataset procesado guardado en `data/processed/`

### Parte 2:
- [ ] `src/models/decision_transformer.py` (copiado/adaptado del TP)
- [ ] `src/data/dataset.py` con `RecommendationDataset` implementado
- [ ] `src/training/trainer.py` con funci√≥n de training
- [ ] `notebooks/02_training.ipynb` con logs y gr√°ficos de loss
- [ ] Modelo entrenado guardado en `results/checkpoints/`

### Parte 3:
- [ ] `src/models/baselines.py` con al menos PopularityRecommender
- [ ] `src/evaluation/metrics.py` con hit_rate, ndcg, mrr
- [ ] `src/evaluation/evaluate.py` con funci√≥n de evaluaci√≥n
- [ ] `notebooks/03_evaluation.ipynb` con tabla de resultados

### Parte 4:
- [ ] `notebooks/04_return_conditioning_experiments.ipynb` ejecutado
- [ ] Gr√°ficos de Return vs Performance
- [ ] An√°lisis por grupo

### Parte 5:
- [ ] `REPORTE.pdf` (3-5 p√°ginas)
- [ ] `README.md` con instrucciones de uso
- [ ] `requirements.txt` con dependencias

---

## üí° CONSEJOS FINALES

### Para aprobar (60-70%):
- Implementar Partes 1, 2, 3 correctamente
- Modelo entrena y mejora (loss baja)
- Reporte b√°sico completo

### Para destacar (80-90%):
- Todo lo anterior +
- Parte 4 completa con an√°lisis detallado
- Comparaci√≥n con m√∫ltiples baselines
- Visualizaciones claras y profesionales

### Para excelencia (95-100%):
- Todo lo anterior +
- Implementaci√≥n propia del transformer (no copiar)
- Experimentos adicionales creativos
- An√°lisis profundo de resultados
- C√≥digo bien documentado y organizado

---

## ‚ùì PREGUNTAS FRECUENTES

**P: ¬øPuedo copiar el c√≥digo del TP directamente?**
R: S√≠ para el modelo (Parte 2). Para el resto, √∫senlo como referencia pero implementen ustedes.

**P: ¬øTengo que implementar todo desde cero?**
R: No. El c√≥digo del modelo est√° completo para copiar. Lo dem√°s es m√°s simple.

**P: No me da tiempo para todo, ¬øqu√© priorizar?**
R: Partes 1, 2, 3 son esenciales. Parte 4 y 5 se pueden reducir.

**P: ¬øC√≥mo debug si algo no funciona?**
R: 
1. Verificar shapes de tensores (print)
2. Empezar con batch_size peque√±o (ej: 8)
3. Verificar que datos no tienen NaN
4. Comparar con c√≥digo de referencia

**P: ¬øQu√© specs de hardware necesito?**
R: Google Colab gratuito es suficiente. O laptop con 8GB RAM.

---

**¬°Buena suerte!** üöÄ

